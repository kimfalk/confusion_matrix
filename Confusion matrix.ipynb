{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Confusion matrix\n",
    "\n",
    "In the field of machine learning, a confusion matrix, also known as a contingency table or an error matrix, is a specific table layout that allows visualization of the performance of an algorithm. Read more on [wikipedia](https://en.wikipedia.org/wiki/Confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Confustion_Matrix(object):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    def __init__(self, true_positive, false_positive, \\\n",
    "         false_negative, true_negative):\n",
    "        self.true_positive = true_positive\n",
    "        self.false_positive = false_positive\n",
    "        self.false_negative = false_negative\n",
    "        self.true_negative = true_negative\n",
    "        \n",
    "    def all(self):\n",
    "        return self.true_negative + self.true_positive + self.false_negative + self.false_positive\n",
    "    def condition_negative(self):\n",
    "        return self.false_positive + self.true_negative\n",
    "    def condition_positive(self):\n",
    "        return self.true_positive + self.false_negative\n",
    "    def predicted_negative(self):\n",
    "        return self.false_negative + self.true_negative\n",
    "    def predicted_positive(self):\n",
    "        return self.false_positive + self.true_positive\n",
    "    \n",
    "    def true_positive_rate(self):\n",
    "        return self.true_positive/self.condition_positive()\n",
    "    def accuracy(self):\n",
    "        return (self.true_positive + self.true_negative) / self.all()\n",
    "    def specificity(self):\n",
    "        return (self.true_negative)/self.condition_negative()\n",
    "    def sensitivity(self):\n",
    "        return self.true_positive_rate()\n",
    "    def recall(self):\n",
    "        return self.true_positive_rate()\n",
    "    def precision(self):\n",
    "        return self.true_positive/self.predicted_positive()\n",
    "    def f_1(self):\n",
    "        return (self.precision()*self.recall())/(self.precision() + self.recall())\n",
    "    \n",
    "    def print(self):\n",
    "        print(\"%.2f       %.2f \\n%.2f       %.2f\"\\\n",
    "              %(self.true_positive, self.false_positive \\\n",
    "              ,self.false_negative, self.true_negative))\n",
    "        print(\"Accuracy = %.2f\" % self.accuracy())\n",
    "        print(\"Specificity = %.2f\" % self.specificity())\n",
    "        print(\"Sensitivity = %.2f\" % self.sensitivity())\n",
    "        print(\"Precision = %.2f\" % self.precision())\n",
    "        print(\"Recall = %.2f\" % self.recall())\n",
    "        print(\"F_1 = %.2f\" % self.f_1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Example 1:\n",
    "\n",
    "Look at the following confusion matrix:\n",
    "\n",
    "|                    | Condition positive | Condition negative | \n",
    "|--------------------|--------------------|--------------------|\n",
    "| Predicted positive | 1                  | 0                  |\n",
    "| Predicted negative | 1                  | 2                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00       0.00 \n",
      "1.00       2.00\n",
      "Accuracy = 0.75\n",
      "Specificity = 1.00\n",
      "Sensitivity = 0.50\n",
      "Precision = 1.00\n",
      "Recall = 0.50\n",
      "F_1 = 0.33\n"
     ]
    }
   ],
   "source": [
    "cm = Confustion_Matrix(1,0,1,2)\n",
    "cm.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2:\n",
    "\n",
    "Look at the following confusion matrix:\n",
    "\n",
    "|                    | Condition positive | Condition negative | \n",
    "|--------------------|--------------------|--------------------|\n",
    "| Predicted positive | 1                  | 0                  |\n",
    "| Predicted negative | 3                  | 1                  |\n",
    "\n",
    "With a large number of predicted negatives, turning out not to be true. Ie. The classifier said it was negative, but in reality it wasn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00       0.00 \n",
      "3.00       1.00\n",
      "Accuracy = 0.40\n",
      "Specificity = 1.00\n",
      "Sensitivity = 0.25\n",
      "Precision = 1.00\n",
      "Recall = 0.25\n",
      "F_1 = 0.20\n"
     ]
    }
   ],
   "source": [
    "cm2 = Confustion_Matrix(1,0, 3,1)\n",
    "cm2.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example 3:\n",
    "\n",
    "Look at the following confusion matrix:\n",
    "\n",
    "|                    | Condition positive | Condition negative | \n",
    "|--------------------|--------------------|--------------------|\n",
    "| Predicted positive | 1                  | 5                  |\n",
    "| Predicted negative | 3                  | 0                  |\n",
    "\n",
    "An even worse result. Almost all classifications are false. This can also be seen\n",
    "in the Accuracy, while sensitivity (true-positive rate) didnt change much, and \n",
    "the Sensitivity (false-negative rate) is the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00       5.00 \n",
      "3.00       0.00\n",
      "Accuracy = 0.11\n",
      "Specificity = 0.00\n",
      "Sensitivity = 0.25\n",
      "Precision = 0.17\n",
      "Recall = 0.25\n",
      "F_1 = 0.10\n"
     ]
    }
   ],
   "source": [
    "cm2 = Confustion_Matrix(1,5, 3,0)\n",
    "cm2.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
